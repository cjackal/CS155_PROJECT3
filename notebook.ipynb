{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from time import process_time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# load custom functions and classes\n",
    "import Utility\n",
    "from Sonnet import Sonnet\n",
    "\n",
    "import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./.gitattributes\n",
      "./CS155_PROJECT3.code-workspace\n",
      "./Dictionary.py\n",
      "./HMM.py\n",
      "./notebook.ipynb\n",
      "./Sonnet.py\n",
      "./Untitled.ipynb\n",
      "./Utility.py\n",
      "./.ipynb_checkpoints\\notebook-checkpoint.ipynb\n",
      "./.ipynb_checkpoints\\Untitled-checkpoint.ipynb\n",
      "./data\\shakespeare.txt\n",
      "./data\\spenser.txt\n",
      "./data\\Syllable_dictionary.txt\n",
      "./data\\syllable_dict_explanation.docx\n",
      "./__pycache__\\Dictionary.cpython-37.pyc\n",
      "./__pycache__\\HMM.cpython-37.pyc\n",
      "./__pycache__\\Sonnet.cpython-37.pyc\n",
      "./__pycache__\\Utility.cpython-37.pyc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('./'):\n",
    "    if dirname[:6]!='./.git':\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1\nFrom fairest creatures we desire increase,\nThat thereby beauty's rose might nev\n"
    }
   ],
   "source": [
    "shakes = open('./data/shakespeare.txt').read()\n",
    "print(shakes[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few exceptions: Sonnets 99, 126, and 145. Number 99 has fifteen lines. Number 126 consists of six couplets, and two blank lines marked with italic brackets; 145 is in iambic tetrameters, not pentameters. In one other variation on the standard structure, found for example in sonnet 29, the rhyme scheme is changed by repeating the second (B) rhyme of quatrain one as the second (F) rhyme of quatrain three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive parsing from the homework helper ftn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'from', 'fairest', 'creatures', 'we', 'desire', 'increase', 'that', 'thereby', 'beautys', 'rose', 'might', 'never', 'die', 'but', 'as', 'the', 'riper', 'should', 'by', 'time', 'decease', 'his', 'tender', 'heir', 'bear', 'memory', 'thou', 'contracted', 'to', 'thine', 'own', 'bright', 'eyes', 'feedst', 'thy', 'lights', 'flame', 'with', 'selfsubstantial', 'fuel', 'making', 'a', 'famine', 'where', 'abundance', 'lies', 'self', 'foe', 'sweet', 'too', 'cruel', 'art', 'now', 'worlds', 'fresh', 'ornament', 'and', 'only', 'herald', 'gaudy', 'spring', 'within', 'bud', 'buriest', 'content', 'churl', 'makst', 'waste', 'in', 'niggarding', 'pity', 'world', 'or', 'else', 'this', 'glutton', 'be', 'eat', 'due', 'grave', 'thee', '2', 'when', 'forty', 'winters', 'shall', 'besiege', 'brow', 'dig', 'deep', 'trenches', 'field', 'youths', 'proud', 'livery', 'so', 'gazed', 'on', 'will']\n"
     ]
    }
   ],
   "source": [
    "obs, obs_map = Utility.parse_observations(shakes)\n",
    "print(list(obs_map.keys())[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the predifined dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>length1</th>\n      <th>length2</th>\n    </tr>\n    <tr>\n      <th>word</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>'gainst</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>'greeing</th>\n      <td>-1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>'scaped</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>'tis</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>'twixt</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         length1 length2\nword                    \n'gainst        1       0\n'greeing      -1       2\n'scaped        1       0\n'tis           1       0\n'twixt         1       0"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syl_dict = Dictionary.syl_predef()  # load predefined syllable dictionary\n",
    "syl_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "154 1 1\n"
    }
   ],
   "source": [
    "l = []\n",
    "for i in range(3205):\n",
    "    if syl_dict.iloc[i][1]!=0:\n",
    "        l.append(abs(syl_dict.iloc[i][1])-abs(syl_dict.iloc[i][0]))\n",
    "print(len(l), max(l), min(l))\n",
    "\n",
    "### Syllable length can vary at most 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Spenser's sonnets into Shakespearean sonnets form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnets = []\n",
    "with open('./data/spenser.txt') as f:\n",
    "    txt = f.read()\n",
    "f.close()\n",
    "lines = txt.split('\\n')\n",
    "lines_copy = lines.copy()\n",
    "for i in range(len(lines)):\n",
    "    lines[i] = re.sub(r\"^\\s+\", '', lines[i])\n",
    "    lines[i] = lines[i].split()\n",
    "sonnet_number = []\n",
    "for i in range(len(lines)):\n",
    "    if len(lines[i])==1:\n",
    "        sonnet_number.append(i)\n",
    "for i in range(len(sonnet_number)):\n",
    "    lines_copy[sonnet_number[i]]=''\n",
    "    lines_copy[sonnet_number[i]+1]=str(Utility.Roman_Decimal(lines[sonnet_number[i]][0]))\n",
    "spenser_new = ''\n",
    "for line in lines_copy:\n",
    "    spenser_new += line + '\\n'\n",
    "with open(\"Spenser.txt\", \"w\") as text:\n",
    "    text.write(spenser_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sonnets from master class 'sonnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Utility.SonnetLoader('shakespeare')\n",
    "for i in range(len(a)):\n",
    "    a[i].SetDict(syl_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[['not', 'from', 'the', 'stars', 'do', 'i', 'my', 'judgement', 'pluck'],\n ['and', 'yet', 'methinks', 'i', 'have', 'astronomy'],\n ['but', 'not', 'to', 'tell', 'of', 'good', 'or', 'evil', 'luck'],\n ['of', 'plagues', 'of', 'dearths', 'or', 'seasons', 'quality'],\n ['nor', 'can', 'i', 'fortune', 'to', 'brief', 'minutes', 'tell'],\n ['pointing', 'to', 'each', 'his', 'thunder', 'rain', 'and', 'wind'],\n ['or', 'say', 'with', 'princes', 'if', 'it', 'shall', 'go', 'well'],\n ['by', 'oft', 'predict', 'that', 'i', 'in', 'heaven', 'find'],\n ['but', 'from', 'thine', 'eyes', 'my', 'knowledge', 'i', 'derive'],\n ['and', 'constant', 'stars', 'in', 'them', 'i', 'read', 'such', 'art'],\n ['as', 'truth', 'and', 'beauty', 'shall', 'together', 'thrive'],\n ['if', 'from', 'thy', 'self', 'to', 'store', 'thou', 'wouldst', 'convert'],\n ['or', 'else', 'of', 'thee', 'this', 'i', 'prognosticate'],\n ['thy', 'end', 'is', \"truth's\", 'and', \"beauty's\", 'doom', 'and', 'date']]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[13].stringform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'now', 'brow'}, {'field', 'held'}, {'lies', 'eyes'}, {'days', 'praise'}, {\"excuse'\", 'use'}, {'mine', 'thine'}, {'old', 'cold'}]\n"
     ]
    }
   ],
   "source": [
    "print(a[1].RhymePair())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "False\n15\n"
    }
   ],
   "source": [
    "print(a[98].IsRegular())\n",
    "print(len(a[98].stringform))            ### Sonnet 99 has 15 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "False\n12\n"
    }
   ],
   "source": [
    "print(a[125].IsRegular())\n",
    "print(len(a[125].stringform))           ### Sonnet 125 has 12 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1109, 936, 574, 3025, 692, 1403],\n",
       " [2719, 2733, 222, 2262, 1696, 1787, 716],\n",
       " [391, 151, 2721, 2247, 2405, 393, 2784, 640],\n",
       " [1323, 2707, 1294, 1696, 210, 1323, 1682],\n",
       " [391, 2753, 535, 2793, 2741, 1895, 364, 926],\n",
       " [983, 2775, 1559, 1024, 3116, 2347, 1116],\n",
       " [1642, 5, 948, 3057, 14, 1554],\n",
       " [2775, 2339, 2775, 1041, 2793, 2775, 2661, 2339, 2807, 588],\n",
       " [2753, 2719, 148, 1816, 2721, 3150, 1104, 1871],\n",
       " [113, 1861, 1302, 2793, 2721, 1133, 2533],\n",
       " [3119, 2741, 1895, 376, 384, 2775, 531],\n",
       " [113, 2707, 460, 1637, 3014, 1398, 1798],\n",
       " [1974, 2721, 3149, 1868, 839, 2749, 1168, 208],\n",
       " [2793, 827, 2721, 3150, 799, 393, 2721, 1192, 113, 2722]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train unsupervised HMM:\n......Converged at 5 iterations\n456.765625 s spent on n_states: 2\n"
    }
   ],
   "source": [
    "from HMM import unsupervised_HMM\n",
    "\n",
    "a_all = a[0].word_to_index\n",
    "for i in range(1,len(a)):\n",
    "    a_all += a[i].word_to_index\n",
    "\n",
    "n_states = [2]\n",
    "N_iters = 100\n",
    "\n",
    "for n_state in n_states:\n",
    "    t = process_time()\n",
    "    HMM, obs_idx = unsupervised_HMM(a_all, n_state, N_iters, verbose=True)\n",
    "    np.savetxt(f'./models/Unsupervised_HMM_A_N_states={n_state}.txt', HMM.A)\n",
    "    np.savetxt(f'./models/Unsupervised_HMM_O_N_states={n_state}.txt', HMM.O)\n",
    "    print(process_time()-t, 's spent on n_states:', n_state)\n",
    "\n",
    "with open('./models/Shakespeare_obs_idx.txt', 'w') as f:\n",
    "    print(obs_idx, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "154"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train unsupervised HMM:\n..........4.9375 s spent on n_states: 2\n"
    }
   ],
   "source": [
    "import HMM_sol\n",
    "\n",
    "safelist = list(range(1,len(a)))\n",
    "\n",
    "a_all = a[0].word_to_index\n",
    "for i in safelist:\n",
    "    a_all += a[i].word_to_index\n",
    "\n",
    "n_states = [2]\n",
    "N_iters = 10\n",
    "\n",
    "for n_state in n_states:\n",
    "    t = process_time()\n",
    "    HMM_sol, obs_idx_sol = HMM_sol.unsupervised_HMM(a_all, n_state, N_iters, verbose=True)\n",
    "    # np.savetxt(f'./data/Unsupervised_HMM_A_N_states={n_state}.txt', np.array(HMM.A))\n",
    "    # np.savetxt(f'./data/Unsupervised_HMM_O_N_states={n_state}.txt', np.array(HMM.O))\n",
    "    print(process_time()-t, 's spent on n_states:', n_state)\n",
    "\n",
    "# with open('./data/Shakespeare_obs_idx.txt', 'w') as f:\n",
    "#     print(obs_idx, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[[0.03952894958418291, 0.9604710504158149],\n [0.6453776154187346, 0.35462238458125583]]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HMM_sol.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_np = np.array(HMM.A)\n",
    "O_np = np.array(HMM.O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./data/Unsupervised_HMM_A.txt', A_np)\n",
    "np.savetxt('./data/Unsupervised_HMM_O.txt', O_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[['recounting', 'then', 'but', 'yield', 'fair', 'hath', 'expense'],\n ['even', 'is', 'keeps', 'glowing', 'that', 'thy', 'that', 'had'],\n ['even', 'spring', 'the', 'can', 'love', 'sometime', 'cause', 'hungry'],\n ['pretty', 'disgrace', 'lack', 'so', 'when', 'unused'],\n ['even', 'blood', 'in', 'i', 'sweet', 'express', 'by', 'a'],\n ['so', 'night', 'to', 'jewel', 'cloud', 'shall', 'my', \"whate'er\"],\n ['even', 'but', 'bent', 'that', 'o', 'are', 'sour', 'wary'],\n ['even', 'that', 'will', \"here's\", 'vows', 'with', 'situation'],\n ['even', 'far', 'this', 'love', 'to', 'question', 'love', 'any'],\n ['even', 'to', 'my', 'and', 'profaned', 'miscalled', 'i'],\n ['even', 'straight', 'be', 'thine', 'art', 'let', 'the', 'thy', 'after'],\n ['even', 'dead', 'be', 'the', 'old', 'of', 'doom', 'impart'],\n ['so', 'fading', 'sweet', 'purging', 'that', 'but', 'such', 'be'],\n ['even', 'that', 'did', 'thunder', 'wing', 'help', 'wish', 'dare']]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from HMM import HiddenMarkovModel\n",
    "\n",
    "A = np.genfromtxt('./data/Unsupervised_HMM_A.txt')\n",
    "O = np.genfromtxt('./data/Unsupervised_HMM_O.txt')\n",
    "HMM = HiddenMarkovModel(A, O)\n",
    "\n",
    "HMM.generate_sonnet(syl_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train unsupervised HMM:\nConverged at 2 iterations\n2146.296875 s spent on n_states: 12\nTrain unsupervised HMM:\nConverged at 2 iterations\n2532.0 s spent on n_states: 14\n"
    }
   ],
   "source": [
    "from HMM import unsupervised_HMM_CV\n",
    "\n",
    "a_all = a[0].word_to_index\n",
    "for i in range(1,len(a)):\n",
    "    a_all += a[i].word_to_index\n",
    "\n",
    "n_states = [12,14]\n",
    "N_iters = 100\n",
    "\n",
    "for n_state in n_states:\n",
    "    t = process_time()\n",
    "    HMM, loglikelihood, obs_idx = unsupervised_HMM_CV(a_all, n_state, N_iters, threshold=0.01, verbose=True)\n",
    "    np.savetxt(f'./models/Unsupervised_HMM_A_N_states={n_state}.txt', HMM.A)\n",
    "    np.savetxt(f'./models/Unsupervised_HMM_O_N_states={n_state}.txt', HMM.O)\n",
    "    with open(f'./models/Unsupervised_HMM_LL_N_states={n_state}.txt', 'w') as fi:\n",
    "        print(loglikelihood, file=fi)\n",
    "    print(process_time()-t, 's spent on n_states:', n_state)\n",
    "\n",
    "# with open('./models/Shakespeare_obs_idx.txt', 'w') as f:\n",
    "#     print(obs_idx, file=f)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}