{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from time import process_time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "./.gitattributes\n./notebook.ipynb\n./data\\shakespeare.txt\n./data\\spenser.txt\n./data\\Syllable_dictionary.txt\n./data\\syllable_dict_explanation.docx\n"
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('./'):\n",
    "    if dirname[:6]!='./.git':\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1\nFrom fairest creatures we desire increase,\nThat thereby beauty's rose might nev\n"
    }
   ],
   "source": [
    "shakes = open('./data/shakespeare.txt').read()\n",
    "print(shakes[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few exceptions: Sonnets 99, 126, and 145. Number 99 has fifteen lines. Number 126 consists of six couplets, and two blank lines marked with italic brackets; 145 is in iambic tetrameters, not pentameters. In one other variation on the standard structure, found for example in sonnet 29, the rhyme scheme is changed by repeating the second (B) rhyme of quatrain one as the second (F) rhyme of quatrain three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive parsing from the homework helper ftn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observations(text):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line.split() for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        obs_elem = []\n",
    "        \n",
    "        for word in line:\n",
    "            word = re.sub(r'[^\\w]', '', word).lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "            \n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "        # Add the encoded sequence.\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['1', 'from', 'fairest', 'creatures', 'we', 'desire', 'increase', 'that', 'thereby', 'beautys', 'rose', 'might', 'never', 'die', 'but', 'as', 'the', 'riper', 'should', 'by', 'time', 'decease', 'his', 'tender', 'heir', 'bear', 'memory', 'thou', 'contracted', 'to', 'thine', 'own', 'bright', 'eyes', 'feedst', 'thy', 'lights', 'flame', 'with', 'selfsubstantial', 'fuel', 'making', 'a', 'famine', 'where', 'abundance', 'lies', 'self', 'foe', 'sweet', 'too', 'cruel', 'art', 'now', 'worlds', 'fresh', 'ornament', 'and', 'only', 'herald', 'gaudy', 'spring', 'within', 'bud', 'buriest', 'content', 'churl', 'makst', 'waste', 'in', 'niggarding', 'pity', 'world', 'or', 'else', 'this', 'glutton', 'be', 'eat', 'due', 'grave', 'thee', '2', 'when', 'forty', 'winters', 'shall', 'besiege', 'brow', 'dig', 'deep', 'trenches', 'field', 'youths', 'proud', 'livery', 'so', 'gazed', 'on', 'will']\n"
    }
   ],
   "source": [
    "obs, obs_map = parse_observations(shakes)\n",
    "print(list(obs_map.keys())[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the given dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>length1</th>\n      <th>length2</th>\n    </tr>\n    <tr>\n      <th>word</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>'gainst</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>'greeing</th>\n      <td>-1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>'scaped</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>'tis</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>'twixt</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         length1 length2\nword                    \n'gainst        1       0\n'greeing      -1       2\n'scaped        1       0\n'tis           1       0\n'twixt         1       0"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syl_dict = pd.read_csv('./data/Syllable_dictionary.txt', sep=' ', names=[\"word\", \"length1\", \"length2\"])\n",
    "syl_dict.fillna(0, inplace=True)\n",
    "# Syllable length of weak ending is negated, NaNs are replaced with 0\n",
    "for i in syl_dict.index:\n",
    "    if syl_dict[\"length2\"][i]==0:                             ### Caveat: There are words with 0 syllables, but they all consists of fixed syllable length.\n",
    "        syl_dict[\"length1\"][i] = int(syl_dict[\"length1\"][i])\n",
    "    else:\n",
    "        if syl_dict[\"length1\"][i][0]=='E':\n",
    "            syl_dict[\"length1\"][i] = -int(syl_dict[\"length1\"][i][1:])\n",
    "            syl_dict[\"length2\"][i] = int(syl_dict[\"length2\"][i])\n",
    "        elif syl_dict[\"length2\"][i][0]=='E':\n",
    "            syl_dict[\"length1\"][i] = int(syl_dict[\"length1\"][i])\n",
    "            syl_dict[\"length2\"][i] = -int(syl_dict[\"length2\"][i][1:])\n",
    "        else:\n",
    "            syl_dict[\"length1\"][i] = int(syl_dict[\"length1\"][i])\n",
    "            syl_dict[\"length2\"][i] = int(syl_dict[\"length2\"][i])\n",
    "syl_dict.set_index(\"word\", inplace=True)\n",
    "\"\"\"\n",
    "length2==0 iff fixed syllable length\n",
    "|length1|<|length2| if variable syllable length\n",
    "\"\"\"\n",
    "syl_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "154 1 1\n"
    }
   ],
   "source": [
    "l = []\n",
    "for i in range(3205):\n",
    "    if syl_dict.iloc[i][1]!=0:\n",
    "        l.append(abs(syl_dict.iloc[i][1])-abs(syl_dict.iloc[i][0]))\n",
    "print(len(l), max(l), min(l))\n",
    "\"\"\"\n",
    "Syllable length can vary at most 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master class 'sonnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SonnetLoader(path):\n",
    "    \"\"\"\n",
    "    Load sonnets from txt, return a list consisting of one sonnet per element.\n",
    "    Each sonnet consists of a list of lines in the sonnet, which is again a list of words in the line.\n",
    "    TODO: There are apostrophes for possessive form of nouns or quotation marks, which must be distinguished from apostrophe for omission.\n",
    "    Probably the easiest cure is deleting them manually before loading the sonnets?\n",
    "    I have checked that sonnet 2, 8 and 145 have a quotation and 14 has a possesive noun (not that no more though).\n",
    "    Why this a problem? Run \"IsRegular\" function on the second sonnet and you will see.\n",
    "    \"\"\"\n",
    "    sonnets = []\n",
    "    if path[0]!='.':\n",
    "        path = './data/' + path + '.txt'\n",
    "    with open(path) as f:\n",
    "        txt = f.read()\n",
    "        lines = txt.split('\\n')\n",
    "        for i in range(len(lines)):\n",
    "            lines[i] = re.sub(\"^\\s+\", '', lines[i]).lower()\n",
    "        beginning = 0\n",
    "        sonnet_is_read = False\n",
    "        i = 0\n",
    "        while i<len(lines):\n",
    "            if lines[i].isdigit():\n",
    "                beginning = i\n",
    "                sonnet_is_read = True\n",
    "            elif len(lines[i])==0:\n",
    "                if sonnet_is_read:\n",
    "                    sonnets.append(lines[beginning+1:i])\n",
    "                    sonnet_is_read = False\n",
    "            i+=1\n",
    "        if sonnet_is_read:\n",
    "            sonnets.append(lines[beginning+1:])\n",
    "    f.close()\n",
    "    for sonnet in sonnets:\n",
    "        for i in range(len(sonnet)):\n",
    "            sonnet[i] = re.sub(r\"[^-'\\w\\s]\", '', sonnet[i]).split()\n",
    "\n",
    "    return [Sonnet(sonnet) for sonnet in sonnets]\n",
    "\n",
    "class Sonnet:\n",
    "    def __init__(self, sonnet):\n",
    "        self.stringform = sonnet        ### sonnet as a list of words itself\n",
    "        is_ending = [[False for _ in range(len(line))] for line in sonnet]\n",
    "        for line in is_ending:\n",
    "            line[-1] = True\n",
    "        self.is_ending = is_ending      ### Encoding the location of the end of each lines (having the same shape as stringform)\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = ''\n",
    "        for line in self.stringform:\n",
    "            for word in line:\n",
    "                s += word+' '\n",
    "            s += '\\n'\n",
    "        return s\n",
    "    \n",
    "    def SetDict(self, df):              ### Set the syllable dictionary.\n",
    "        self.dict = df                  ### Temporary format: rows indexed by the words, with two columns of possible syllables\n",
    "        idxmap = {}\n",
    "        for i, s in enumerate(self.dict.index.to_numpy()):\n",
    "            idxmap[s] = i\n",
    "        self.index_map = idxmap         ### {key:value}={word:idx}\n",
    "        word_to_idx = []\n",
    "        for line in self.stringform:\n",
    "            word_to_idx_line = []\n",
    "            for word in line:\n",
    "                word_to_idx_line.append(self.index_map[word])\n",
    "            word_to_idx.append(word_to_idx_line)\n",
    "        self.word_to_index = word_to_idx    ### sonnet with words replaced with the corresponding idx\n",
    "\n",
    "    def IsRegular(self):\n",
    "        \"\"\"\n",
    "        Check if the given sonnet is in regular (pentameter) form.\n",
    "        Must set the syllable dictionary beforehand.\n",
    "        With a little modification, can assign a valid syllable length for the words.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = self.dict\n",
    "            isregular = False\n",
    "            regularity = 0\n",
    "            if len(self.stringform)==14:\n",
    "                for line in self.stringform:\n",
    "                    syllable_counter_min = 0\n",
    "                    syllable_counter_max = 0\n",
    "                    for i in range(len(line)):\n",
    "                        if i<len(line)-1:\n",
    "                            if df.loc[line[i]][1]==0:\n",
    "                                syllable_counter_max += df.loc[line[i]][0]\n",
    "                                syllable_counter_min += df.loc[line[i]][0]\n",
    "                            else:\n",
    "                                if df.loc[line[i]][0]<0:\n",
    "                                    syllable_counter_max += df.loc[line[i]][1]\n",
    "                                    syllable_counter_min += df.loc[line[i]][1]\n",
    "                                elif df.loc[line[i]][1]<0:\n",
    "                                    syllable_counter_max += df.loc[line[i]][0]\n",
    "                                    syllable_counter_min += df.loc[line[i]][0]\n",
    "                                else:\n",
    "                                    syllable_counter_max += df.loc[line[i]][1]\n",
    "                                    syllable_counter_min += df.loc[line[i]][0]\n",
    "                        else:\n",
    "                            if df.loc[line[i]][1]==0:\n",
    "                                syllable_counter_max += df.loc[line[i]][0]\n",
    "                                syllable_counter_min += df.loc[line[i]][0]\n",
    "                            else:\n",
    "                                syllable_counter_max += abs(df.loc[line[i]][1])\n",
    "                                syllable_counter_min += abs(df.loc[line[i]][0])\n",
    "                    if syllable_counter_min <= 10 <= syllable_counter_max:\n",
    "                        regularity += 1\n",
    "            if regularity==14:\n",
    "                isregular = True\n",
    "            return isregular\n",
    "\n",
    "        except AttributeError:\n",
    "            print(\"Set the syllable dictionary to use.\")\n",
    "\n",
    "    def WordList(self):\n",
    "        s = set()\n",
    "        for line in self.stringform:\n",
    "            s |= set(line)\n",
    "        return s\n",
    "    \n",
    "    def RhymePair(self):\n",
    "        pair = []\n",
    "        paring = [[0,2],[1,3],[4,6],[5,7],[8,10],[9,11],[12,13]]\n",
    "        for couple in paring:\n",
    "            i, j = couple\n",
    "            pair.append({self.stringform[i][-1], self.stringform[j][-1]})\n",
    "        return pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = SonnetLoader('shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[{'now', 'brow'}, {'held', 'field'}, {'eyes', 'lies'}, {'days', 'praise'}, {'use', \"excuse'\"}, {'thine', 'mine'}, {'old', 'cold'}]\n"
    }
   ],
   "source": [
    "print(a[1].RhymePair())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].SetDict(syl_dict)\n",
    "a[0].IsRegular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "False\n15\n"
    }
   ],
   "source": [
    "a[98].SetDict(syl_dict)\n",
    "print(a[98].IsRegular())\n",
    "print(len(a[98].stringform))            ### Sonnet 99 has 15 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "False\n12\n"
    }
   ],
   "source": [
    "a[125].SetDict(syl_dict)\n",
    "print(a[125].IsRegular())\n",
    "print(len(a[125].stringform))           ### Sonnet 125 has 12 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[[1109, 936, 574, 3025, 692, 1403],\n [2719, 2733, 222, 2262, 1696, 1787, 716],\n [391, 151, 2721, 2247, 2405, 393, 2784, 640],\n [1323, 2707, 1294, 1696, 210, 1323, 1682],\n [391, 2753, 535, 2793, 2741, 1895, 364, 926],\n [983, 2775, 1559, 1024, 3116, 2347, 1116],\n [1642, 5, 948, 3057, 14, 1554],\n [2775, 2339, 2775, 1041, 2793, 2775, 2661, 2339, 2807, 588],\n [2753, 2719, 148, 1816, 2721, 3150, 1104, 1871],\n [113, 1861, 1302, 2793, 2721, 1133, 2533],\n [3119, 2741, 1895, 376, 384, 2775, 531],\n [113, 2707, 460, 1637, 3014, 1398, 1798],\n [1974, 2721, 3149, 1868, 839, 2749, 1168, 208],\n [2793, 827, 2721, 3150, 799, 393, 2721, 1192, 113, 2722]]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-dcfc35c9cfb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mN_iters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mHMM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munsupervised_HMM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Print the transition matrix.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhn3\\Documents\\GitHub\\CS155_PROJECT3\\HMM.py\u001b[0m in \u001b[0;36munsupervised_HMM\u001b[1;34m(X, n_states, N_iters)\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[0mHMM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsupervised_learning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mHMM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\juhn3\\Documents\\GitHub\\CS155_PROJECT3\\HMM.py\u001b[0m in \u001b[0;36munsupervised_learning\u001b[1;34m(self, X, N_iters)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mO_denom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                 \u001b[0malphas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juhn3\\Documents\\GitHub\\CS155_PROJECT3\\HMM.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, normalize)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mst\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0malphas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA_start\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mO\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from HMM import unsupervised_HMM\n",
    "\n",
    "safelist = list(range(2,20))\n",
    "safelist.remove(7)\n",
    "safelist.remove(13)\n",
    "\n",
    "a[0].SetDict(syl_dict)\n",
    "a_all = a[0].word_to_index\n",
    "for i in safelist:\n",
    "    a[i].SetDict(syl_dict)\n",
    "    a_all += a[i].word_to_index\n",
    "\n",
    "n_states = 4\n",
    "N_iters = 10\n",
    "\n",
    "HMM = unsupervised_HMM(a_all, n_states, N_iters)\n",
    "\n",
    "# Print the transition matrix.\n",
    "print(\"Transition Matrix:\")\n",
    "print('#' * 70)\n",
    "for i in range(len(HMM.A)):\n",
    "    print(''.join(\"{:<12.3e}\".format(HMM.A[i][j]) for j in range(len(HMM.A[i]))))\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "# Print the observation matrix. \n",
    "print(\"Observation Matrix:  \")\n",
    "print('#' * 70)\n",
    "for i in range(len(HMM.O)):\n",
    "    print(''.join(\"{:<12.3e}\".format(HMM.O[i][j]) for j in range(len(HMM.O[i]))))\n",
    "print('')\n",
    "print('')"
   ]
  }
 ]
}